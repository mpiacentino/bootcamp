{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2\n",
    "\n",
    "(c) 2016 Justin Bois and Griffin Chure. This work is licensed under a [Creative Commons Attribution License CC-BY 4.0](https://creativecommons.org/licenses/by/4.0/). All code contained herein is licensed under an [MIT license](https://opensource.org/licenses/MIT).\n",
    "\n",
    "*This exercise was generated from a Jupyter notebook.  You can download the notebook [here](l17_exercise_2.ipynb).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import bioinfo_dicts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercises 2.3 and 2.4  were inspired by [Libeskind-Hadas and Bush, *Computing for Biologists*, Cambridge University Press, 2014](https://www.cs.hmc.edu/CFB).\n",
    "\n",
    "For all problems except for the git practice, we will work with real data from the *Salmonella enterica* genome.  The section of the genome we will work with is in the file `~git/bootcamp/data/salmonella_spi1_region.fna`.  I cut it out of the [full genome](http://www.ncbi.nlm.nih.gov/nucleotide/821161554).  It contains *Salmonella* pathogenicity island I (SPI1), which is contains genes for surface receptors for host-pathogen interactions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2.1: Finish the Git practice exercises\n",
    "\n",
    "If you have not already, finish the [practice exercises with git](../lessons/l12_practice_with_git.html#Practice-1:-Adding-a-file-to-your-bootcamp-repository)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.1 solution\n",
    "\n",
    "This involved making files and doing commits, so there are no real coding solutions. I hope you got it all to work!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2.2: Parsing a FASTA file\n",
    "\n",
    "There are packages, like [Biopython](http://biopython.org/) and [scikit-bio](http://scikit-bio.org) for processing files you encounter in bioinformatics.  In this problem, though, we will work on our file I/O skills.  \n",
    "\n",
    "**a)** Use command line tools to investigate the FASTA file.  You will notice that the first line begins with a `>`, signifying that the line contains information about the sequence.  The remainder of the lines are the sequence itself.\n",
    "\n",
    "**b)** Use the file I/O skill you have learned to read in the sequence and store it as a single string with no gaps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.2: solution\n",
    "\n",
    "**a)** A quick look using `less` indicates that this is a valid FASTA file.  I did a quick check to see how many sequences there are by searching for the `>` symbol using `grep`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grep: ../data/salmonella_spi1_region.fna: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!grep \">\" ../data/salmonella_spi1_region.fna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there is a single record.  So, when we read it in, we just need to skip the first line and read on until we get the full record."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b)** Because the file is not too big, we can just read it all in at once.  We can then find the first newline character to trim off the first line, which is the description text.  Finally, we just delete all newline characters to get our sequence.  (This is just one of many ways to do this.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AAAACCTTAGTAACTGGACTGCTGGGATTTTTCAGCCTGGATACGCTGGTAGATCTCTTCACGATGGACAGAAACTTCTTTCGGGGCGTTCACGCCAATACGCACCTGGTTGCCCTTCACCCCTAAAACTGTCACGGTGACCTCATCGCCAATCATGAGGGTCTCACCAACTCGACGAGTCAGAATCAGCATTCTTTGCTCCTTGAAAGATTAAAAGAGTCGGGTCTCTCTGTATCCCGGCATTATCCATCATATAACGCCAAAAAGTAAGCGATGACAAACACCTTAGGTGTAAGCAGTCATGGCATTACATTCTGTTAAACCTAAGTTTAGCCGATATACAAAACTTCAACCTGACTTTATCGTTGTCGATAGCGTTGACGTAAACGCCGCAGCACGGGCTGCGGCGCCAACGAACGCTTATAATTATTGCAATTTTGCGCTGACCCAGCCTTGTACACTGGCTAACGCTGCAGGCAGAGCTGCCGCATCCGTACCAC'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read all the lines into a list\n",
    "with open('data/salmonella_spi1_region.fna', 'r') as f:\n",
    "    file_str = f.read()\n",
    "\n",
    "# Cut off first line, but keep descriptor\n",
    "descriptor = file_str[:file_str.find('\\n')]\n",
    "file_str = file_str[file_str.find('\\n')+1:]\n",
    "\n",
    "# Eliminate newlines\n",
    "seq = file_str.replace('\\n', '')\n",
    "\n",
    "# Take a look at the first 500 bases to make sure we got it right.\n",
    "seq[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2.3: Pathogenicity islands\n",
    "Pathogenicity islands are often marked by different GC content than the rest of the genome.  We will try to locate the pathogenicity island(s) in our section of the *Salmonella* genome by computing GC content.\n",
    "\n",
    "**a)** Write a function that divides a sequence into blocks and computes the GC content for each block, returning a tuple.  The function signature should look like\n",
    "\n",
    "    gc_blocks(seq, block_size)\n",
    "    \n",
    "To be clear, if `seq = 'ATGACTACGT'` and `block_size = 4`, the blocks to be considered are\n",
    "\n",
    "    ATGA\n",
    "    CTAC\n",
    "    \n",
    "and the function should return `(0.25, 0.5)`.  Note that the blocks are non-overlapping and that we don't bother with the end of the sequence that does not fit completely in a block."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b)** Write a function that takes as input a sequence, block size, and a theshold GC content, and returns the original sequence where every base in a block with GC content above threshold is capitalized and every base below the threshold is lowercase.  You would call the function like this:\n",
    "\n",
    "    mapped_seq = gc_map(seq, block_size, gc_thresh)\n",
    "\n",
    "For example, \n",
    "\n",
    "    gc_map('ATGACTACGT', 4, 0.4)\n",
    "\n",
    "returns `'atgaCTAC'`.  Note that bases not included in GC blocks are truncated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c)** Use the `gc_map()` function to generate a GC content map for the *Salmonella* sequence with `block_size = 1000` and `gc_thresh = 0.45`.  Where do you think the pathogenicity island is?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d)** Write the GC-mapped sequence (with upper and lower characters) to a new FASTA file.  Use the same description line (which began with a `>` in the original FASTA file), and have line breaks every 60 characters in the sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.3: Solution\n",
    "**a)** The function is fairly simple.  We loop through the sequence with a stride equal to the block size, computing the GC content for each subsequence of that length.  We start with a function to compute GC content for a sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gc_content(seq):\n",
    "    \"\"\"GC content of a given sequence\"\"\"\n",
    "    seq = seq.upper()\n",
    "    return (seq.count('G') + seq.count('C')) / len(seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we write the looping function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gc_blocks(seq, block_size):\n",
    "    \"\"\"\n",
    "    Divide sequence into non-overlapping blocks\n",
    "    and compute GC content of each block.\n",
    "    \"\"\"\n",
    "    blocks = []\n",
    "    for i in range(0, len(seq) - (len(seq) % block_size), block_size):\n",
    "        blocks.append(gc_content(seq[i:i+block_size]))\n",
    "    return tuple(blocks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b)** We just use our already-written `gc_content()` function to decide how to modify the string of the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gc_map(seq, block_size, gc_thresh):\n",
    "    \"\"\"Give back seq with lowercase letters where GC content is low.\"\"\"\n",
    "\n",
    "    out_seq = ''\n",
    "\n",
    "    # Determine GC content of each block and change string accordingly\n",
    "    for i in range(0, len(seq) - (len(seq) % block_size), block_size):\n",
    "        if gc_content(seq[i:i+block_size]) < gc_thresh:\n",
    "            out_seq += seq[i:i+block_size].lower()\n",
    "        else:\n",
    "            out_seq += seq[i:i+block_size].upper()\n",
    "\n",
    "    return out_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c)** Let's do it for *Salmonella*!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sal_gcmap = gc_map(seq, 1000, 0.45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To save on display space, we will not display the sequence here.  Scrolling through the GC map file generated in the next part, the pathogenicity island appears to occur about a quarter of the way into this subsequence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d)** To write the file out, we use the fact that we conveniently kept the description text when we parsed the *Salmonella* FASTA file in the first place.  We then just write the `sal_gcmap` string in blocks of 60.  We have to make sure to ge t the last few bases as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write the result\n",
    "with open('salmonella_spi1_region_gc_map.fna', 'w') as f:\n",
    "    # Write description text\n",
    "    f.write(descriptor + '\\n')\n",
    "\n",
    "    # Write sequence in blocks of 60\n",
    "    i = 0\n",
    "    while i < len(sal_gcmap) - 59:\n",
    "        f.write(sal_gcmap[i:i+60] + '\\n')\n",
    "        i += 60\n",
    "    \n",
    "    # Write last line\n",
    "    f.write(sal_gcmap[i:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll take a quick look to see it worked out ok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">gi|821161554|gb|CP011428.1| Salmonella enterica subsp. enterica strain YU39, complete genome, subsequence 3000000 to 3200000\n",
      "AAAACCTTAGTAACTGGACTGCTGGGATTTTTCAGCCTGGATACGCTGGTAGATCTCTTC\n",
      "ACGATGGACAGAAACTTCTTTCGGGGCGTTCACGCCAATACGCACCTGGTTGCCCTTCAC\n",
      "CCCTAAAACTGTCACGGTGACCTCATCGCCAATCATGAGGGTCTCACCAACTCGACGAGT\n",
      "CAGAATCAGCATTCTTTGCTCCTTGAAAGATTAAAAGAGTCGGGTCTCTCTGTATCCCGG\n",
      "CATTATCCATCATATAACGCCAAAAAGTAAGCGATGACAAACACCTTAGGTGTAAGCAGT\n",
      "CATGGCATTACATTCTGTTAAACCTAAGTTTAGCCGATATACAAAACTTCAACCTGACTT\n",
      "TATCGTTGTCGATAGCGTTGACGTAAACGCCGCAGCACGGGCTGCGGCGCCAACGAACGC\n",
      "TTATAATTATTGCAATTTTGCGCTGACCCAGCCTTGTACACTGGCTAACGCTGCAGGCAG\n",
      "AGCTGCCGCATCCGTACCACCGGCTTGCGCCATGTCCGGACGACCGCCACCCTTACCGCC\n",
      "...\n",
      "ACGCATTTCTCCCGTGCAGGTCACATTTGCCCGACACGGCGGGGCAAGAGGCTTGAACAG\n",
      "ACGTTCATTTTCCGTAAAACTGGCGTAATGTAAGCGTTTACCCACTATAGGTATTATCAT\n",
      "GGCGACCATAAAAGATGTAGCCCGACTGGCCGGTGTTTCAGTCGCCACCGTTTCTCGCGT\n",
      "TATTAACGATTCGCCAAAAGCCAGCGAAGCGTCCCGGCTGGCGGTAACCAGCGCAATGGA\n",
      "GTCCCTGAGCTATCACCCTAACGCCAACGCGCGCGCGCTGGCACAGCAGGCAACGGAAAC\n",
      "CCTCGGTCTGGTGGTCGGCGACGTTTCCGATCCTTTTTTCGGCGCGATGGTGAAAGCCGT\n",
      "TGAACAGGTGGCGTATCACACCGGCAATTTTTTACTGATTGGCAACGGGTATCATAACGA\n",
      "ACAAAAAGAGCGTCAGGCTATTGAACAGTTGATTCGTCATCGTTGCGCAGCGTTAGTGGT\n",
      "GCACGCCAAAATGATTCCGGATGCGGACCTGGCCTCATTAATGAAGCAAATCCCCGGCAT\n",
      "GGTGCTGATTAACCGCATTT"
     ]
    }
   ],
   "source": [
    "!head salmonella_spi1_region_gc_map.fna\n",
    "print('...')\n",
    "!tail salmonella_spi1_region_gc_map.fna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2.4: ORF detection\n",
    "\n",
    "**a)** Write a function, `longest_orf()`, that takes a DNA sequence as input and finds the longest open reading frame (ORF) in the sequence (we will not consider reverse complements).  A sequence fragment constitutes an ORF if the following are true.\n",
    "\n",
    "1. It begins with `ATG`.\n",
    "2. It ends with any of `TGA`, `TAG`, or `TAA`.\n",
    "3. The total number of bases is a multiple of 3.\n",
    "\n",
    "Note that the sequence `ATG` may appear in the middle of an ORF.  So, for example,\n",
    "\n",
    "    GGATGATGATGTAAAAC\n",
    "\n",
    "has two ORFs, `ATGATGATGTAA` and `ATGATGTAA`.  You would return the first one, since it is longer of these two.\n",
    "\n",
    "*Hint: The statement for this problem is a bit ambiguous as it is written.  What other specification might you need for this function?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b)** Use your function to find the longest ORF from the section of the *Salmonella* genome we are investigating."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c)** Write a function that converts a DNA sequence into a protein sequence.  The dictionaries in the `bioinfo_dicts` module may be useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d)** Translate the longest ORF you generated in part (b) and perform a [BLAST search](http://blast.ncbi.nlm.nih.gov/).  Search for the protein sequence (a blastp query).  What gene is it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**e)** [challenge] Modify your function to return the `n` longest ORFs.  Compute the five longest ORFs for the *Salmonella* genome section we are working with.  Perform BLAST searches on them.  What are they?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.4: solution\n",
    "\n",
    "**a)** Something was missing in the specification.  Namely, what do we do if there are two ORFs of the same longest length?  Do we return the first one, second one, or both?  I am arbitrarily choosing to return the one with the 3$'$-most starting index.  \n",
    "\n",
    "Looking ahead to part (e), I will first write a function to return all ORFs that are not entirely included in a longer ORFs.  For ease of storage and comparison, I will simply store the ORFS as the index of the start of the ORF and the noninclusive index of the last.\n",
    "\n",
    "Let's now discuss the algorithm we'll use.  There are more efficient ways of finding ORFs, but I will choose a very clear way.  We'll first find all start codons.  For each start codon, we will find the first in-register stop codon.  If there is an in-register stop codon, we store this start-stop pair.  At the end, we sort them, longest to shortest.\n",
    "\n",
    "So, we really have three functions we'll use.  `find_all_starts(seq)` will return the indices of all start codons in a sequence.  `find_next_in_register_stop(seq)` will scan the seq and return the exclusive final index of the next in register stop codon. In other words, and ORF starting at index `start` is given by\n",
    "\n",
    "    seq[start:find_next_in_register_stop(seq)]\n",
    "\n",
    "If there is no such codon, `find_next_in_register_stop()` returns `-1`.  Finally, `all_orfs(seq)` returns the sorted tuple of 2-tuples containing the start/stop pairs of the ORFs.\n",
    "\n",
    "In coming lessons, we will learn about test-driven development. I will use TDD principles for designing these functions, writing the test cases first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test_find_all_starts():\n",
    "    assert find_all_starts('') == tuple()\n",
    "    assert find_all_starts('GGAGACGACGCAAAAC'.lower()) == tuple()\n",
    "    assert find_all_starts('AAAAAAATGAAATGAGGGGGGTATG'.lower()) == (6, 11, 22)\n",
    "    assert find_all_starts('GGATGATGATGTAAAAC'.lower()) == (2, 5, 8)\n",
    "    assert find_all_starts('GGATGCATGATGTAGAAC'.lower()) == (2, 6, 9)\n",
    "    assert find_all_starts('GGGATGATGATGGGATGGTGAGTAGGGTAAG'.lower()) == \\\n",
    "                                                               (3, 6, 9, 14)\n",
    "    assert find_all_starts('GGGatgatgatgGGatgGtgaGtagGGACtaaG'.lower()) == \\\n",
    "                                                               (3, 6, 9, 14)    \n",
    "    \n",
    "    \n",
    "def test_find_first_in_register_stop():\n",
    "    assert find_first_in_register_stop('') == -1\n",
    "    assert find_first_in_register_stop('GTAATAGTGA'.lower()) == -1\n",
    "    assert find_first_in_register_stop('AAAAAAAAAAAAAAATAAGGGTAA'.lower()) == 18\n",
    "    assert find_first_in_register_stop('AAAAAACACCGCGTGTACTGA'.lower()) == 21\n",
    "    \n",
    "    \n",
    "def test_all_orfs():\n",
    "    assert all_orfs('') == tuple()\n",
    "    assert all_orfs('GGAGACGACGCAAAAC') == tuple()\n",
    "    assert all_orfs('AAAAAAATGAAATGAGGGGGGTATG') == ((6, 15),)\n",
    "    assert all_orfs('GGATGATGATGTAAAAC') == ((2, 14),)\n",
    "    assert all_orfs('GGATGCATGATGTAGAAC') == ((6, 15),)\n",
    "    assert all_orfs('GGGATGATGATGGGATGGTGAGTAGGGTAAG') == ((3, 21),)\n",
    "    assert all_orfs('GGGatgatgatgGGatgGtgaGtagGGACtaaG') == ((14, 32), (3, 21))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start with the `find_all_starts()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_all_starts(seq):\n",
    "    \"\"\"Find all start codons in sequence\"\"\"\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we'll fail the test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-55021aff17ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_find_all_starts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-64-efdb07b08548>\u001b[0m in \u001b[0;36mtest_find_all_starts\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest_find_all_starts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mfind_all_starts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mfind_all_starts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GGAGACGACGCAAAAC'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mfind_all_starts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'AAAAAAATGAAATGAGGGGGGTATG'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m22\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mfind_all_starts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GGATGATGATGTAAAAC'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_find_all_starts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll write the function. I'll write is using the `re` modules which is a power string processing module that uses regular expressions. We [covered this in bootcamp last year](http://justinbois.github.io/bootcamp/2015/lessons/l16_regular_expressions.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_all_starts(seq):\n",
    "    \"\"\"Find the starting index of all start codons in a lowercase seq\"\"\"\n",
    "    # Compile regex for start codons\n",
    "    regex_start = re.compile('atg')\n",
    "        \n",
    "    # Find the indices of all start codons\n",
    "    starts = []\n",
    "    for match in regex_start.finditer(seq):\n",
    "        starts.append(match.start())\n",
    "        \n",
    "    return tuple(starts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's see if it passes the tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_find_all_starts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yay!  We passed!  However, since we did not learn regular expressions this year, I will write a function that finds all start codons that does not use them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_all_starts(seq):\n",
    "    \"\"\"Find the starting index of all start codons in a lowercase seq\"\"\"\n",
    "    # Initialize array of indices of start codons\n",
    "    starts = []\n",
    "    \n",
    "    # Find index of first start codon (remember, find() returns -1 if not found)\n",
    "    i = seq.find('atg')\n",
    "    \n",
    "    # Keep looking for subsequence incrementing starting point of search\n",
    "    while i >= 0:\n",
    "        starts.append(i)\n",
    "        i = seq.find('atg', i + 1)\n",
    "        \n",
    "    return tuple(starts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's test this new `find_all_starts()` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_find_all_starts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It passed! Yay!\n",
    "\n",
    "Now, let's move on to the next function, which finds the first in-register stop codon. Again, we fail, and then write the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-c857d333ce02>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtest_find_first_in_register_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-64-efdb07b08548>\u001b[0m in \u001b[0;36mtest_find_first_in_register_stop\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest_find_first_in_register_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mfind_first_in_register_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mfind_first_in_register_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GTAATAGTGA'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mfind_first_in_register_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'AAAAAAAAAAAAAAATAAGGGTAA'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m18\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def find_first_in_register_stop(seq):\n",
    "    return None\n",
    "\n",
    "test_find_first_in_register_stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice, beautiful failure.  Now, we'll write the function and test it. Again, I'll demonstrate the power of the `re` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_first_in_register_stop(seq):\n",
    "    \"\"\"\n",
    "    Find first stop codon on lowercase seq that starts at an index\n",
    "    that is divisible by three\n",
    "    \"\"\"\n",
    "    # Compile regexes for stop codons\n",
    "    regex_stop = re.compile('(taa|tag|tga)')\n",
    "    \n",
    "    # Stop codon iterator\n",
    "    stop_iterator = regex_stop.finditer(seq)\n",
    "\n",
    "    # Find next stop codon that is in register\n",
    "    for stop in stop_iterator:\n",
    "        if stop.end() % 3 == 0:\n",
    "            return stop.end()\n",
    "        \n",
    "    # Return -1 if we failed to find a stop codon\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the test..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_find_first_in_register_stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! It passes. Now, I'll write it without regular expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_first_in_register_stop(seq):\n",
    "    \"\"\"\n",
    "    Find first stop codon on seq that starts at an index\n",
    "    that is divisible by three\n",
    "    \"\"\"\n",
    "\n",
    "    seq = seq.lower()\n",
    "\n",
    "    # Scan sequence for stop codon\n",
    "    i = 0\n",
    "    while i < len(seq) - 2 and seq[i:i+3] not in ('taa', 'tag', 'tga'):\n",
    "        i += 3\n",
    "\n",
    "    # If before end, found codon, return end of codon\n",
    "    if i < len(seq) - 2:\n",
    "        return i + 3\n",
    "    else: # Failed to find stop codon\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test this function to make sure it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_find_first_in_register_stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passage!  Finally, we apply TDD to write `all_orfs()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def all_orfs(seq):\n",
    "    \"\"\"Return all ORFs of a sequence.\"\"\"\n",
    "    # Make sure sequence is all lower case\n",
    "    seq = seq.lower()\n",
    "        \n",
    "    # Find the indices of all start codons\n",
    "    start_inds = find_all_starts(seq)\n",
    "        \n",
    "    # Keep track of stops\n",
    "    stop_inds = []\n",
    "        \n",
    "    # Initialze ORFs.  Each entry in list is [ORF length, ORF start, ORF stop]\n",
    "    orfs = []\n",
    "        \n",
    "    # For each start codon, find the next stop codon in register\n",
    "    for start in start_inds:\n",
    "        relative_stop = find_first_in_register_stop(seq[start:])\n",
    "        \n",
    "        if relative_stop != -1:\n",
    "            # Index of stop codon\n",
    "            stop = start + relative_stop\n",
    "            \n",
    "            # If already had stop, a longer ORF contains this one\n",
    "            if stop not in stop_inds:\n",
    "                orfs.append((relative_stop, start, stop))\n",
    "                stop_inds.append(stop)\n",
    "                        \n",
    "    # Get sorted list of ORF length\n",
    "    orfs = sorted(orfs, reverse=True)\n",
    "    \n",
    "    # Remove lengths\n",
    "    for i, orf in enumerate(orfs):\n",
    "        orfs[i] = (orf[1], orf[2])\n",
    "    \n",
    "    return tuple(orfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the tests...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_all_orfs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passage!  We have succeed in generating an ordered list of the ORFs.  Now, let's get what the problem specified, the longest ORF.  Of course, we start with writing tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_longest_orf():\n",
    "    assert longest_orf('') == ''\n",
    "    assert longest_orf('GGAGACGACGCAAAAC') == ''\n",
    "    assert longest_orf('AAAAAAATGAAATGAGGGGGGTATG') == 'ATGAAATGA'\n",
    "    assert longest_orf('GGATGATGATGTAAAAC') == 'ATGATGATGTAA'\n",
    "    assert longest_orf('GGATGCATGATGTAGAAC') == 'ATGATGTAG'\n",
    "    assert longest_orf('GGGATGATGATGGGATGGTGAGTAGGGTAAG') == 'ATGATGATGGGATGGTGA'\n",
    "    assert longest_orf('GGGatgatgatgGGatgGtgaGtagGGACtaaG') == \\\n",
    "                                                        'atgGtgaGtagGGACtaa'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll fail them...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-91-75f52821fc25>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtest_longest_orf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-90-ddc3d3850231>\u001b[0m in \u001b[0;36mtest_longest_orf\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest_longest_orf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mlongest_orf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mlongest_orf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GGAGACGACGCAAAAC'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mlongest_orf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'AAAAAAATGAAATGAGGGGGGTATG'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'ATGAAATGA'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mlongest_orf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GGATGATGATGTAAAAC'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'ATGATGATGTAA'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def longest_orf(seq):\n",
    "    return None\n",
    "\n",
    "test_longest_orf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll write our function, and then test it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def longest_orf(seq):\n",
    "    \"\"\"Longest ORF of a sequence.\"\"\"\n",
    "    orfs = all_orfs(seq)\n",
    "    \n",
    "    if len(orfs) == 0:\n",
    "        return ''\n",
    "    else:\n",
    "        return seq[orfs[0][0]:orfs[0][1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_longest_orf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passage!  Success!  We now have a reliable function for computing the longest ORF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b)** We simple use our new function to find the longest ORF of the *Salmonella* sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ATGACCAACTACAGCCTGCGCGCACGCATGATGATTCTGATCCTGGCCCCGACCGTCCTGATAGGTTTGCTGCTCAGTATCTTTTTTGTAGTGCACCGCTATAACGACCTGCAGCGTCAACTGGAAGATGCCGGCGCCAGTATTATTGAACCGCTCGCCGTCTCCAGCGAATATGGTATGAACTTACAAAACCGGGAGTCTATCGGCCAACTTATCAGCGTCCTGCACCGCAGACACTCTGATATTGTGCGGGCGATTTCCGTTTATGACGATCATAACCGTCTGTTTGTAACGTCTAATTTCCATCTGGACCCCTCACAGATGCAGCTTCCCGCCGGAGCGCCGTTTCCACGTCGTCTGAGCGTTGATCGCCACGGCGATATTATGATTCTGCGCACCCCAATTATCTCGGAGAGCTATTCGCCGGACGAGTCAGCGATTGCTGACGCGAAAAATACCAAAAATATGCTGGGGTATGTGGCGCTTGAACTGGATCTCAAGTCGGTCAGGCTACAGCAATACAAAGAGATTTTTATCTCCAGCGTGATGATGCTTTTTTGTATTGGCATTGCGCTGATCTTTGGCTGGCGGCTTATGCGCGATGTCACCGGGCCTATCCGTAATATGGTGAATACCGTTGACCGCATTCGCCGCGGACAACTGGATAGCCGGGTGGAAGGATTTATGCTGGGCGAACTGGATATGCTGAAAAACGGCATTAATTCCATGGCGATGTCGCTTGCCGCCTATCACGAAGAGATGCAGCATAATATCGATCAGGCCACTTCGGACCTGCGTGAAACCCTTGAGCAGATGGAAATCCAAAACGTTGAGCTGGATCTGGCGAAAAAGCGTGCCCAGGAAGCGGCGCGTATTAAGTCGGAGTTCCTGGCGAACATGTCGCACGAACTGCGAACGCCGCTGAACGGCGTCATTGGCTTTACCCGCCTGACATTAAAAACGGAGCTGAATCCCACCCAGCGCGACCATCTGAACACCATTGAGCGTTCCGCGAATAATCTGCTGGCGATCATTAATGACGTGCTTGATTTCTCCAAGCTGGAAGCCGGTAAGCTCATTCTGGAAAGTATCCCTTTTCCACTGCGTAATACGCTGGATGAAGTGGTTACGCTGCTGGCTCACTCGTCGCATGATAAAGGGCTGGAGTTGACGTTAAATATTAAAAACGACGTCCCGGATAATGTGATTGGCGACCCGCTGCGCCTGCAACAGGTCATTACTAATCTGGTGGGTAATGCCATTAAGTTCACCGAGAGTGGCAATATCGACATTCTGGTAGAAAAGCGGGCGCTCAGTAACACCAAAGTACAGATTGAAGTGCAGATCCGCGATACGGGGATCGGCATTCCGGAACGCGACCAGTCGCGACTGTTTCAGGCGTTTCGCCAGGCCGATGCCAGTATTTCTCGCCGTCACGGCGGCACCGGGCTTGGGCTGGTGATTACGCAAAAGCTGGTCAACGAAATGGGCGGGGATATCTCTTTCCACAGCCAGCCTAATCGCGGCTCGACCTTCTGGTTTCATATTAATCTTGATCTTAACCCAAATGTCATTATTGACGGGCCGTCGACCGCGTGTCTGGCCGGGAAACGGCTGGCTTATGTCGAACCGAATGCTACCGCCGCGCAATGTACCCTGGATCTACTGAGCGACACGCCGGTGGAGGTGGTTTACAGCCCGACCTTCTCCGCGCTGCCGTTAGCGCACTACGATATTATGATTTTGAGCGTTCCGGTGACCTTCCGCGAGCCGCTCACCATGCAGCATGAACGTCTGGCGAAAGCAGCGTCAATGACGGACTTTCTACTGCTGGCGCTACCTTGCCATGCGCAAATTAACGCCGAAAAGCTGAAACAAGGAGGCGCGGCGGCCTGTCTGTTAAAACCATTGACGTCAACGCGCCTGTTGCCAGCGCTGACGGAATATTGCCAGTTGAATCACCATCCTGAACCGCTGCTAATGGATACCAGTAAAATCACCATGACGGTTATGGCGGTTGATGATAATCCCGCTAATCTGAAGCTTATCGGCGCGTTACTGGAAGATAAAGTCCAGCACGTAGAGCTTTGTGATAGCGGACATCAGGCGGTGGATCGGGCGAAACAAATGCAGTTTGATCTGATTTTGATGGATATTCAGATGCCGGATATGGACGGCATACGCGCCTGCGAATTGATTCACCAGCTTCCTCATCAGCAGCAAACACCGGTTATTGCCGTTACGGCACATGCGATGGCCGGGCAAAAAGAGAAGTTGCTCAGCGCGGGCATGAACGACTATCTGGCTAAACCGATAGAAGAAGAGAAGTTGCATAATCTGTTGCTGCGCTATAAACCTGGCGCCAACGTAGCAGCGCGCCTGATGGCGCCGGAACCAGCTGAATTTATCTTCAATCCGAATGCAACGCTCGACTGGCAGCTTGCGCTCCGCCAGGCTGCCGGTAAGCCCGATCTGGCGCGGGATATGCTGCAAATGCTGATTGATTTTCTGCCGGAAGTGCGCAACAAAATTGAAGAACAACTGGTGGGAGAAAATCCCAACGGCCTGGTCGATCTGGTCCATAAGCTACACGGGAGCTGCGGCTATAGCGGCGTACCGCGGATGAAGAACCTTTGCCAGCTTATTGAGCAACAGCTTCGCAGCGGCGTCCACGAAGAGGAGCTGGAGCCTGAGTTTCTGGAGCTGCTGGATGAGATGGATAATGTCGCGCGTGAAGCGAAGAAGATATTAGGCTGA'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute it\n",
    "salmonella_orf = longest_orf(seq)\n",
    "\n",
    "# Look at it\n",
    "salmonella_orf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c)** We can use the `codons` dictionary in the `bioinfo_dicts` module to do the translation.  With this in hand, we can write our `translate()` function.  We will scan the DNA sequence, generate a list of amino acids, and then join them into a protein sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def translate(seq):\n",
    "    \"\"\"Translate a DNA sequence into protein\"\"\"\n",
    "\n",
    "    # Make sure sequence is upper case\n",
    "    seq = seq.upper()\n",
    "    \n",
    "    # Find start codon\n",
    "    i = 0\n",
    "    while i < len(seq) + 2 and seq[i:i+3] != 'ATG':\n",
    "        i += 1\n",
    "\n",
    "    # Translate until the stop codon or end of string\n",
    "    prot = []\n",
    "    while i < len(seq) - 2 and seq[i:i+3] not in ('TAA', 'TGA', 'TAG'):\n",
    "        prot.append(bioinfo_dicts.codons[seq[i:i+3]])\n",
    "        i += 3\n",
    "\n",
    "    return ''.join(prot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d)** We can now translate the protein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MTNYSLRARMMILILAPTVLIGLLLSIFFVVHRYNDLQRQLEDAGASIIEPLAVSSEYGMNLQNRESIGQLISVLHRRHSDIVRAISVYDDHNRLFVTSNFHLDPSQMQLPAGAPFPRRLSVDRHGDIMILRTPIISESYSPDESAIADAKNTKNMLGYVALELDLKSVRLQQYKEIFISSVMMLFCIGIALIFGWRLMRDVTGPIRNMVNTVDRIRRGQLDSRVEGFMLGELDMLKNGINSMAMSLAAYHEEMQHNIDQATSDLRETLEQMEIQNVELDLAKKRAQEAARIKSEFLANMSHELRTPLNGVIGFTRLTLKTELNPTQRDHLNTIERSANNLLAIINDVLDFSKLEAGKLILESIPFPLRNTLDEVVTLLAHSSHDKGLELTLNIKNDVPDNVIGDPLRLQQVITNLVGNAIKFTESGNIDILVEKRALSNTKVQIEVQIRDTGIGIPERDQSRLFQAFRQADASISRRHGGTGLGLVITQKLVNEMGGDISFHSQPNRGSTFWFHINLDLNPNVIIDGPSTACLAGKRLAYVEPNATAAQCTLDLLSDTPVEVVYSPTFSALPLAHYDIMILSVPVTFREPLTMQHERLAKAASMTDFLLLALPCHAQINAEKLKQGGAAACLLKPLTSTRLLPALTEYCQLNHHPEPLLMDTSKITMTVMAVDDNPANLKLIGALLEDKVQHVELCDSGHQAVDRAKQMQFDLILMDIQMPDMDGIRACELIHQLPHQQQTPVIAVTAHAMAGQKEKLLSAGMNDYLAKPIEEEKLHNLLLRYKPGANVAARLMAPEPAEFIFNPNATLDWQLALRQAAGKPDLARDMLQMLIDFLPEVRNKIEEQLVGENPNGLVDLVHKLHGSCGYSGVPRMKNLCQLIEQQLRSGVHEEELEPEFLELLDEMDNVAREAKKILG'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(salmonella_orf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doing a BLAST search on this protein indicates that it is a histidine kinase involved in signaling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**e)** We already are computing all of the ORFs.  We an therefore just add a kwarg to our `longest_orf()` function to get the `n` longest ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def longest_orf(seq, n=1):\n",
    "    \"\"\"Longest ORF of a sequence.\"\"\"\n",
    "    orfs = all_orfs(seq)\n",
    "    \n",
    "    if len(orfs) == 0:\n",
    "        return ''\n",
    "    elif n == 1 or len(orfs) == 1:\n",
    "        return seq[orfs[0][0]:orfs[0][1]]\n",
    "    else:\n",
    "        return_list = []\n",
    "        for i in range(min(n, len(orfs))):\n",
    "            return_list.append(seq[orfs[i][0]:orfs[i][1]])\n",
    "        return tuple(return_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll compute the ORFs, translate them, and make a FASTA file to submit for a BLAST search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute ORFs\n",
    "orfs = longest_orf(seq, n=5)\n",
    "\n",
    "# Translate them\n",
    "prots = []\n",
    "for orf in orfs:\n",
    "    prots.append(translate(orf))\n",
    "    \n",
    "# Make a FASTA file\n",
    "with open('sal_seqs.faa', 'w') as f:\n",
    "    for i, prot in enumerate(prots):\n",
    "        f.write('> {0:d}\\n'.format(i))\n",
    "        f.write(prot + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take a look at it to see what I did with the above code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 0\r\n",
      "MTNYSLRARMMILILAPTVLIGLLLSIFFVVHRYNDLQRQLEDAGASIIEPLAVSSEYGMNLQNRESIGQLISVLHRRHSDIVRAISVYDDHNRLFVTSNFHLDPSQMQLPAGAPFPRRLSVDRHGDIMILRTPIISESYSPDESAIADAKNTKNMLGYVALELDLKSVRLQQYKEIFISSVMMLFCIGIALIFGWRLMRDVTGPIRNMVNTVDRIRRGQLDSRVEGFMLGELDMLKNGINSMAMSLAAYHEEMQHNIDQATSDLRETLEQMEIQNVELDLAKKRAQEAARIKSEFLANMSHELRTPLNGVIGFTRLTLKTELNPTQRDHLNTIERSANNLLAIINDVLDFSKLEAGKLILESIPFPLRNTLDEVVTLLAHSSHDKGLELTLNIKNDVPDNVIGDPLRLQQVITNLVGNAIKFTESGNIDILVEKRALSNTKVQIEVQIRDTGIGIPERDQSRLFQAFRQADASISRRHGGTGLGLVITQKLVNEMGGDISFHSQPNRGSTFWFHINLDLNPNVIIDGPSTACLAGKRLAYVEPNATAAQCTLDLLSDTPVEVVYSPTFSALPLAHYDIMILSVPVTFREPLTMQHERLAKAASMTDFLLLALPCHAQINAEKLKQGGAAACLLKPLTSTRLLPALTEYCQLNHHPEPLLMDTSKITMTVMAVDDNPANLKLIGALLEDKVQHVELCDSGHQAVDRAKQMQFDLILMDIQMPDMDGIRACELIHQLPHQQQTPVIAVTAHAMAGQKEKLLSAGMNDYLAKPIEEEKLHNLLLRYKPGANVAARLMAPEPAEFIFNPNATLDWQLALRQAAGKPDLARDMLQMLIDFLPEVRNKIEEQLVGENPNGLVDLVHKLHGSCGYSGVPRMKNLCQLIEQQLRSGVHEEELEPEFLELLDEMDNVAREAKKILG\r\n",
      "> 1\r\n",
      "MNESFDKDFSNHTPMMQQYLKLKAQHPEILLFYRMGDFYELFYDDAKRASQLLDISLTKRGASAGEPIPMAGIPHHAVENYLAKLVNQGESVAICEQIGDPATSKGPVERKVVRIVTPGTISDEALLQERQDNLLAAIWQDGKGYGYATLDISSGRFRLSEPADRETMAAELQRTNPAELLYAEDFAEMALIEGRRGLRRRPLWEFEIDTARQQLNLQFGTRDLVGFGVENASRGLCAAGCLLQYVKDTQRTSLPHIRSITMERQQDSIIMDAATRRNLEITQNLAGGVENTLAAVLDCTVTPMGSRMLKRWLHMPVRNTDILRERQQTIGALQDTVSELQPVLRQVGDLERILARLALRTARPRDLARMRHAFQQLPELHAQLETVDSAPVQALRKKMGDFAELRDLLERAIIDAPPVLVRDGGVIAPGYHEELDEWRALADGATDYLDRLEIRERERTGLDTLKVGYNAVHGYYIQISRGQSHLAPINYVRRQTLKNAERYIIPELKEYEDKVLTSKGKALALEKQLYDELFDLLLPHLADLQQSANALAELDVLVNLAERAWTLNYTCPTFTDKPGIRITEGRHPVVEQVLNEPFIANPLNLSPQRRMLIITGPNMGGKSTYMRQTALIALLAYIGSYVPAQNVEIGPIDRIFTRVGAADDLASGRSTFMVEMTETANILHNATENSLVLMDEIGRGTSTYDGLSLAWACAENLANKIKALTLFATHYFELTQLPEKMEGVANVHLDALEHGDTIAFMHSVQDGAASKSYGLAVAALAGVPKEVIKRARQKLRELESISPNAAATQVDGTQMSLLAAPEETSPAVEALENLDPDSLTPRQALEWIYRLKSLV\r\n",
      "> 2\r\n",
      "MSYTPMSDLGQQGLFDITRTLLQQPDLASLSEALSQLVKRSALADSAGIVLWQAQSQRAQYYATRENGRPVEYEDETVLAHGPVRRILSRPDALHCNFHEFTETWPQLAASGLYPEFGHYCLLPLAAEGRIFGGCEFIRQEDRPWSEKEYDRLHTFTQIVGVVAEQIQNRVNNNVDYDLLCRERDNFRILVAITNAVLSRLDIDELVSEVAKEIHHYFNIDAISIVLRSHRKNKLNIYSTHYLDEHHPAHEQSEVDEAGTLTERVFKSKEMLLINLNERDPLAPYERMLFDTWGNQIQTLCLLPLMSGKTMLGVLKLAQCEEKVFTTANLKLLRQIAERVAIAVDNALAYQEIHRLKERLVDENLALTEQLNNVDSEFGEIIGRSEAMYNVLKQVEMVAQSDSTVLILGETGTGKELIARAIHNLSGRSGRRMVKMNCAAMPAGLLESDLFGHERGAFTGASAQRIGRFELADKSSLFLDEVGDMPLELQPKLLRVLQEQEFERLGSNKLIQTDVRLIAATNRDLKKMVADREFRNDLYYRLNVFPIQLPPLRERPEDIPLLVKAFTFKIARRMGRNIDSIPAETLRTLSSMEWPGNVRELENVVERAVLLTRGNVLQLSLPDITAVTPDTSPVATESAKEGEDEYQLIIRVLKETNGVVAGPKGAAQRLGLKRTTLLSRMKRLGIDKDALA\r\n",
      "> 3\r\n",
      "MKKISLPKIGIRPVIDGRRMGVRESLEEQTMNMAKATAALITEKIRHACGAQVECVIADTCIAGMAESAACEEKFSSQNVGVTITVTPCWCYGSETIDMDPMRPKAIWGFNGTERPGAVYLAAALAAHSQKGIPAFSIYGHDVQDADDTSIPADVEEKLLRFARAGLAVASMKGKSYLSVGGVSMGIAGSIVDHNFFESWLGMKVQAVDMTELRRRIDQKIYDEAELEMALAWADKNFRYGEDQNASQYKRNEAQNRAVLKESLLMAMCIRDMMQGNKTLADKGLVEESLGYNAIAAGFQGQRHWTDQYPNGDTAEALLNSSFDWNGVREPFVVATENDSLNGVAMLFGHQLTGTAQIFADVRTYWSPEAVERVTGQALSGLAEHGIIHLINSGSAALDGACKQRDSEGKPTMKPHWEISQQEADACLAATEWCPAIHEYFRGGGYSSRFLTEGGVPFTMTRVNIIKGLGPVLQIAEGWSVELPKAMHDQLDARTNSTWPTTWFAPRLTGKGPFTDVYSVMANWGANHGVLTIGHVGADFITLAAMLRIPVCMHNVEEAKIYRPSAWAAHGMDIEGQDYRACQNYGPLYKR\r\n",
      "> 4\r\n",
      "MPHFNPVPVSNKKFVFDDFILNMDGSLLRSEKKVNIPPKEYAVLVILLEAAGEIVSKNTLLDQVWGDAEVNEESLTRCIYALRRILSEDKEHRYIETLYGQGYRFNRPVVVVSPPAPQPTTHTLAILPFQMQDQVQSESLHYSIVKGLSQYAPFGLSVLPVTITKNCRSVKDILELMDQLRPDYYISGQMIPDGNDNIVQIEIVRVKGYHLLHQESIKLIEHQPASLLQNKIANLLLRCIPGLRWDTKQISELNSIDSTMVYLRGKHELNQYTPYSLQQALKLLTQCVNMSPNSIAPYCALAECYLSMAQMGIFDKQNAMIKAKEHAIKATELDHNNPQALGLLGLINTIHSEYIVGSLLFKQANLLSPISADIKYYYGWNLFMAGQLEEALQTINECLKLDPTRAAAGITKLWITYYHTGIDDAIRLGDELRSQHLQDNPILLSMQVMFLSLKGKHELARKLTKEISTQEITGLIAVNLLYAEYCQNSERALPTIREFLESEQRIDNNPGLLPLVLVAHGEAIAEKMWNKFKNEDNIWFKRWKQDPRLIKLR\r\n"
     ]
    }
   ],
   "source": [
    "!cat sal_seqs.faa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon doing the BLAST search, I found that the genes are:\n",
    "\n",
    "|Length rank| Description|\n",
    "|:---:|:---:|\n",
    "|1 | histine kinase |\n",
    "|2 | DNA rapair protein MutS|\n",
    "|3 | formate hydrogenlyase transcriptional activator|\n",
    "|4 | L-fucose isomerase |\n",
    "|5 | transcriptional regulator HilA (invasion regulator)|"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
