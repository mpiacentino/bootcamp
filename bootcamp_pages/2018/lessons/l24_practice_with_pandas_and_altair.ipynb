{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 24: Practice with Pandas and Altair\n",
    "\n",
    "(c) 2018 Justin Bois. With the exception of pasted graphics, where the source is noted, this work is licensed under a [Creative Commons Attribution License CC-BY 4.0](https://creativecommons.org/licenses/by/4.0/). All code contained herein is licensed under an [MIT license](https://opensource.org/licenses/MIT).\n",
    "\n",
    "This document was prepared at [Caltech](http://www.caltech.edu) with financial support from the [Donna and Benjamin M. Rosen Bioengineering Center](http://rosen.caltech.edu).\n",
    "\n",
    "<img src=\"caltech_rosen.png\">\n",
    "\n",
    "*This lesson was generated from a Jupyter notebook.  You can download the notebook [here](l24_practice_with_pandas_and_altair.ipynb).*\n",
    "\n",
    "<br /> <br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice 1: Axes with logarithmic scale\n",
    "\n",
    "Sometimes you need to plot your data with a logarithmic scale. As an example, let's consider the classic genetic switch engineered by Jim Collins and coworkers ([Gardner, et al., *Nature*, **403**, 339, 2000](http://www.nature.com/nature/journal/v403/n6767/full/403339a0.html)). This genetic switch was incorporated into *E. coli* and is inducible by adjusting the concentration of the lactose analog IPTG. The readout is the fluorescence intensity of GFP.\n",
    "\n",
    "Let's load in some data that have the IPTG concentrations and GFP fluorescence intensity. The data are in the file `~/git/data/collins_switch.csv`. Let's look at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Data digitized from Fig. 5a of Gardner, et al., *Nature*, **403**, 339, 2000. The last column gives the standard error of the mean normalized GFP intensity.\n",
      "iptg (mM),normalized gfp expression,sem\n",
      "0.001000,0.004090,0.003475\n",
      "0.010000,0.010225,0.002268\n",
      "0.020000,0.022495,0.004781\n",
      "0.030000,0.034765,0.003000\n",
      "0.040000,0.067485,0.006604\n",
      "0.040000,0.668712,0.087862\n",
      "0.060000,0.740286,0.045853\n",
      "0.100000,0.840491,0.058986\n",
      "0.300000,0.936605,0.026931\n",
      "0.600000,0.961145,0.093553\n",
      "1.000000,0.940695,0.037624\n",
      "3.000000,0.852761,0.059035\n",
      "6.000000,0.910020,0.051052\n",
      "10.000000,0.893661,0.042773\n"
     ]
    }
   ],
   "source": [
    "!cat data/collins_switch.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It has two rows of non-data. Then, Column 1 is the IPTG concentration, column 2 is the normalized GFP expression level, and the last column is the standard error of the mean normalized GFP intensity. This gives the error bars, which we will look at in the next exercise. For now, we will just plot IPTG versus normalized GFP intensity.\n",
    "\n",
    "In looking at the data set, note that there are two entries for [IPTG] = 0.04 mM. At this concentration, the switch happens, and there are two populations of cells, one with high expression of GFP and one with low. The two data points represent these two populations of cells.\n",
    "\n",
    "Now, let's make a plot of IPTG versus GFP.\n",
    "\n",
    ">1. Load in the data set using Pandas. Make sure you use the `comment` kwarg of pd.read_csv() properly.\n",
    "2. Make a plot of normalized GFP intensity (y-axis) versus IPTG concentration (x-axis). When you make your plot, you may wish to label your axes differently than the column headings in the original data file.\n",
    "\n",
    "Now that you have done that, there are some problems with the plot. It is really hard to see the data points with low concentrations of IPTG. In fact, looking at the data set, the concentration of IPTG varies over four orders of magnitude. When you have data like this, it is wise to plot them on a logarithmic scale. You can specify an axis in a `Chart` to have a logarithmic scale using the `scale=alt.Scale(type='log')` kwarg in your encoding for the *x* or *y* variables. For this data set, it is definitely best to have the x-axis on a logarithmic scale. Remake the plot you just did with the x-axis logarithmically scaled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice 2: Plots with error bars\n",
    "\n",
    "The data set also contains the standard error of the mean, or SEM. The SEM is often displayed on plots as error bars. Now construct the plot with error bars.\n",
    "\n",
    ">1. Add columns `error_low` and `error_high` to the `DataFrame` containing the Collins data. These will set the bottoms and tops of the error bars. You should base the values in these columns on the standard error of the mean (`sem`). Assuming a Gaussian model the 95% confidence interval is Â±1.96 times the s.e.m.\n",
    "2. Make a plot with the measured expression levels and the error bars."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
