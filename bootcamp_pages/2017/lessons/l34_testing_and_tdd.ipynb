{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 34: Testing and test-driven development\n",
    "\n",
    "(c) 2017 Justin Bois and Davi Ortega. This work is licensed under a [Creative Commons Attribution License CC-BY 4.0](https://creativecommons.org/licenses/by/4.0/). All code contained herein is licensed under an [MIT license](https://opensource.org/licenses/MIT).\n",
    "\n",
    "*This tutorial was generated from a Jupyter notebook.  You can download the notebook [here](l34_testing_and_tdd.ipynb).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# py.test gives the testing functionality\n",
    "import pytest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test-driven development**, or **TDD**, is a paradigm for developing software.  The idea is that a programmer thinks about a design specification for a bit of code, usually a function.  I.e., she lays out what the input and output should be.  She then writes a test (that will fail) for the bit of code.  She then writes or updates the code to pass the test.  She does this **incrementally** as she builds her code.  Let's try this by example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An example of TDD\n",
    "\n",
    "We will write a function that computes the number of negatively charged residues in a protein.  In other words, we count up the number of glutamate (`E`) and aspartate (`D`) residues.\n",
    "\n",
    "We'll call the function `n_neg()`, and will just make an empty function for now as a placeholder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def n_neg(seq):\n",
    "    \"\"\"Number of negative residues a protein sequence\"\"\"\n",
    "\n",
    "    # Do nothing for now\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll write a very simple test.  It is just a conditional expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_neg('E') == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We failed the test!  But before we focus on the test failure, let's think about what we just did.  We defined the prototype for the function.  We know we want it to take in a sequence (a string) and return an integer.  So, in building the test, we have designed the interface for the function.\n",
    "\n",
    "Back to the test failure.  We now have a test we would like our function to pass, and we will now revisit the function to write it so that it will pass the test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def n_neg(seq):\n",
    "    \"\"\"Number of negative residues a protein sequence\"\"\"\n",
    "\n",
    "    # Count E's and D's, since these are the negative residues\n",
    "    return seq.count('E') + seq.count('D')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll try out test again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_neg('E') == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hurray!  We passed our first test.  Now, lets write some more test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(n_neg('E') == 1)\n",
    "print(n_neg('D') == 1)\n",
    "print(n_neg('') == 0)\n",
    "print(n_neg('ACKLWTTAE') == 1)\n",
    "print(n_neg('DDDDEEEE') == 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our function appears to be working well.  But let's think carefully about how we could break it.  What if we had lowercase letters?  I.e., what would we want \n",
    "\n",
    "    n_neg('acklwttae')\n",
    "\n",
    "to return?  Do we allow lower case?  This is an example where coming up with tests is how we define the interface.  We weren't done designing it at the first pass!\n",
    "\n",
    "Let's say we want to allow lower case symbols.  So, before we mess with our function, let's write a test!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_neg('acklwttae') == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We failed, as expected.  Now, back to the function. We will add a line to convert the input sequence to uppercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def n_neg(seq):\n",
    "    \"\"\"Number of negative residues a protein sequence\"\"\"\n",
    "\n",
    "    # Convert sequence to upper case\n",
    "    seq = seq.upper()\n",
    "    \n",
    "    # Count E's and D's, since these are the negative residues\n",
    "    return seq.count('E') + seq.count('D')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to run ALL of our tests again.  We have to make sure *everything* passes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(n_neg('E') == 1)\n",
    "print(n_neg('D') == 1)\n",
    "print(n_neg('') == 0)\n",
    "print(n_neg('ACKLWTTAE') == 1)\n",
    "print(n_neg('DDDDEEEE') == 8)\n",
    "print(n_neg('acklwttae') == 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great!  This works now.\n",
    "\n",
    "You can see how the cycle proceeds.  Right now, we might be happy with our function, but as we use it in whatever context we are working in, use cases we have not thought of might creep up.  For everything that happens, or there is a bug you find, *write another test that covers it*.  Importantly, *any time* you update your code, you need to run *all* of your tests!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The assert statement\n",
    "\n",
    "In our example, we used a bunch of print statements to check our tests.  Conveniently, Python have a built-in way to do your tests using the **`assert`** keyword.  For example, our first test using **`assert`** is as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert n_neg('E') == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This ran without issue.  Now, let's try asserting something we know will fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-188264dd8bc1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mn_neg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'E'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert n_neg('E') == 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get an `AssertionError`, indicating that our assertion failed.  We can even append the **`assert`** statement with a comment describing the error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Failed on sequence of length 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-b6ed3249ba8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mn_neg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'E'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Failed on sequence of length 1'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: Failed on sequence of length 1"
     ]
    }
   ],
   "source": [
    "assert n_neg('E') == 2, 'Failed on sequence of length 1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we see the basic syntax of **`assert`** statements.  After **`assert`**, we have a conditional expression that evaluates to `True` or `False`.  If it evaluates `False`, an `AssertionError` is raised, meaning that the test was failed.  Optionally, the conditional expression can be followed with a comma and a string that describes how it failed.  So, we could write all of our tests together as a series of assertions.  Actually, it would be best to write a *function* that does the testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_n_neg():\n",
    "    \"\"\"Perform unit tests on n_neg.\"\"\"\n",
    "\n",
    "    assert n_neg('E') == 1\n",
    "    assert n_neg('D') == 1\n",
    "    assert n_neg('') == 0\n",
    "    assert n_neg('ACKLWTTAE') == 1\n",
    "    assert n_neg('DDDDEEEE') == 8\n",
    "    assert n_neg('acklwttae') == 1\n",
    "\n",
    "\n",
    "# Run all the tests\n",
    "test_n_neg()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent!  Everything passed!\n",
    "\n",
    "It might be a little underwhelming that Python exits silently when all our tests pass. Fortunately, someone else felt that way too and implemented a testing tool that is more into positive reinforcement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducing  pytest\n",
    "\n",
    "The `pytest` (a.k.a. `py.test`) module comes with a standard Anaconda installation and is useful tool for automating your testing.  It gives detailed feedback on your tests.  You can read its documentation [here](http://pytest.org).\n",
    "\n",
    "The `unittest` module from the standard library and `nose` are two other major testing packages for Python.  All three are in common usage.  We use `pytest` here because I think it is the easiest to use and understand.\n",
    "\n",
    "Pytest is not only a module but also a command line application that searches for tests in your code, runs them and let you know if they fail, and if they pass; finally some positive reinforcement. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using pytest \n",
    "\n",
    "To take the most advantage of pytest, we should take a step back, get out of the IPython environment and write the functions we have been working with in this lesson to a `.py` file. We'll call it `seq_features.py`. Its content:\n",
    "\n",
    "```python\n",
    "def n_neg(seq):\n",
    "    \"\"\"Number of negative residues a protein sequence\"\"\"\n",
    "\n",
    "    # Convert sequence to upper case\n",
    "    seq = seq.upper()\n",
    "    \n",
    "    # Count E's and D's, since these are the negative residues\n",
    "    return seq.count('E') + seq.count('D')\n",
    "    \n",
    "def test_n_neg():\n",
    "    \"\"\"Perform unit tests on n_neg.\"\"\"\n",
    "\n",
    "    assert n_neg('E') == 1\n",
    "    assert n_neg('D') == 1\n",
    "    assert n_neg('') == 0\n",
    "    assert n_neg('ACKLWTTAE') == 1\n",
    "    assert n_neg('DDDDEEEE') == 8\n",
    "    assert n_neg('acklwttae') == 1\n",
    "```\n",
    "\n",
    "Now, pytest makes it easy to verify if all these tests pass or not:\n",
    "\n",
    "```\n",
    "$ pytest seq_features.py\n",
    "========================== test session starts ==========================\n",
    "platform darwin -- Python 3.6.1, pytest-3.0.7, py-1.4.33, pluggy-0.4.0\n",
    "rootdir: /Users/Justin/git/programming_bootcamp/2017/lessons, inifile:\n",
    "collected 1 items \n",
    "\n",
    "seq_features.py .\n",
    "\n",
    "======================= 1 passed in 0.00 seconds ========================\n",
    "```\n",
    "\n",
    "**Hint:** try the option **`-v`** for even more sugar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pytest is smart\n",
    "\n",
    "Pytest is such a smart application that you don't even need to tell it explicitly which file it should look at. By default, pytest will search for files starting with `test_` or `tests_` and ending with `.py` in the whole directory tree.\n",
    "\n",
    "It is a good idea to separate your test suite from your code. So let's make another file, named `test_seq_features.py` and place just the function with the assert statements. You can delete them now from the `seq_features.py`.\n",
    "\n",
    "You directory should have now these two files:\n",
    "\n",
    "`seq_features.py`\n",
    "```python\n",
    "def n_neg(seq):\n",
    "    \"\"\"Number of negative residues a protein sequence\"\"\"\n",
    "\n",
    "    # Convert sequence to upper case\n",
    "    seq = seq.upper()\n",
    "    \n",
    "    # Count E's and D's, since these are the negative residues\n",
    "    return seq.count('E') + seq.count('D')\n",
    "```\n",
    "\n",
    "and  \n",
    "\n",
    "`test_seq_features.py`\n",
    "```python\n",
    "import seq_features\n",
    "\n",
    "def test_n_neg():\n",
    "    \"\"\"Perform unit tests on seq_features.n_neg.\"\"\"\n",
    "\n",
    "    assert seq_features.n_neg('E') == 1\n",
    "    assert seq_features.n_neg('D') == 1\n",
    "    assert seq_features.n_neg('') == 0\n",
    "    assert seq_features.n_neg('ACKLWTTAE') == 1\n",
    "    assert seq_features.n_neg('DDDDEEEE') == 8\n",
    "    assert seq_features.n_neg('acklwttae') == 1\n",
    "```\n",
    "\n",
    "Note that because the `n_neg()` function is in a different file than the tests, we must import the `seq_features` module. Now you can run the test as:\n",
    "\n",
    "```\n",
    "$ pytest -v\n",
    "========================== test session starts ==========================\n",
    "platform darwin -- Python 3.6.1, pytest-3.0.7, py-1.4.33, pluggy-0.4.0\n",
    "rootdir: /Users/Justin/git/programming_bootcamp/2017/lessons, inifile:\n",
    "collected 1 items \n",
    "\n",
    "test_seq_features.py .\n",
    "\n",
    "======================= 1 passed in 0.03 seconds ========================\n",
    "```\n",
    "\n",
    "Note that there is no need to pass the argument to pytest. This is particularly useful if you have many types of tests, and different applications. Since it is all about organization, now we can separate those tests into more meaningful functional units:\n",
    "\n",
    "`test_seq_features.py`\n",
    "```python\n",
    "import seq_features\n",
    "\n",
    "def test_n_neg_for_single_E_or_D():\n",
    "    \"\"\"Perform unit tests on n_neg.\"\"\"\n",
    "\n",
    "    assert seq_features.n_neg('E') == 1\n",
    "    assert seq_features.n_neg('D') == 1\n",
    "    \n",
    "def test_n_neg_for_empty_sequence():\n",
    "    assert seq_features.n_neg('') == 0\n",
    "\n",
    "def test_n_neg_for_longer_sequences():\n",
    "    assert seq_features.n_neg('ACKLWTTAE') == 1\n",
    "    assert seq_features.n_neg('DDDDEEEE') == 8\n",
    "\n",
    "def test_n_neg_for_lower_case_sequences():\n",
    "    assert seq_features.n_neg('acklwttae') == 1\n",
    "```\n",
    "\n",
    "And now we can run the tests again.\n",
    "\n",
    "```\n",
    "$ pytest -v\n",
    "============================== test session starts ===============================\n",
    "platform darwin -- Python 3.6.1, pytest-3.0.7, py-1.4.33, pluggy-0.4.0 -- /Users/Justin/anaconda/bin/python\n",
    "cachedir: .cache\n",
    "rootdir: /Users/Justin/git/programming_bootcamp/2017/lessons, inifile:\n",
    "collected 4 items \n",
    "\n",
    "test_seq_features.py::test_n_neg_for_single_E_or_D PASSED\n",
    "test_seq_features.py::test_n_neg_for_empty_sequence PASSED\n",
    "test_seq_features.py::test_n_neg_for_longer_sequences PASSED\n",
    "test_seq_features.py::test_n_neg_for_lower_case_sequences PASSED\n",
    "\n",
    "============================ 4 passed in 0.03 seconds ============================\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The obvious thing to do next is to test some other cases. Think: what else could go wrong?\n",
    "What if there is an invalid residue in the sequence? How we expect our code to behave?\n",
    "\n",
    "These and other semi-existential questions will be addressed in the next lesson."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
