{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lessons 23 and 24: Practice with Numpy and Matplotlib\n",
    "\n",
    "(c) 2017 Justin Bois. This work is licensed under a [Creative Commons Attribution License CC-BY 4.0](https://creativecommons.org/licenses/by/4.0/). All code contained herein is licensed under an [MIT license](https://opensource.org/licenses/MIT).\n",
    "\n",
    "*This tutorial was generated from a Jupyter notebook.  You can download the notebook [here](l23-24_practice_with_numpy_2_solution.ipynb).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice 1: Axes with logarithmic scale\n",
    "\n",
    "Sometimes you need to plot your data with a logarithmic scale. As an example, let's consider the classic genetic switch engineered by Jim Collins and coworkers ([Gardner, et al., *Nature*, **403**, 339, 2000](http://www.nature.com/nature/journal/v403/n6767/full/403339a0.html)). This genetic switch was incorporated into *E. coli* and is inducible by adjusting the concentration of the lactose analog IPTG. The readout is the fluorescence intensity of GFP.\n",
    "\n",
    "Let's load in some data that have the IPTG concentrations and GFP fluorescence intensity. The data are in the file `~/git/data/collins_switch.csv`. Let's look at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Data digitized from Fig. 5a of Gardner, et al., *Nature*, **403**, 339, 2000. The last column gives the standard error of the mean normalized GFP intensity.\r\n",
      "iptg (mM),normalized gfp expression,sem\r\n",
      "0.001000,0.004090,0.003475\r\n",
      "0.010000,0.010225,0.002268\r\n",
      "0.020000,0.022495,0.004781\r\n",
      "0.030000,0.034765,0.003000\r\n",
      "0.040000,0.067485,0.006604\r\n",
      "0.040000,0.668712,0.087862\r\n",
      "0.060000,0.740286,0.045853\r\n",
      "0.100000,0.840491,0.058986\r\n",
      "0.300000,0.936605,0.026931\r\n",
      "0.600000,0.961145,0.093553\r\n",
      "1.000000,0.940695,0.037624\r\n",
      "3.000000,0.852761,0.059035\r\n",
      "6.000000,0.910020,0.051052\r\n",
      "10.000000,0.893661,0.042773\r\n"
     ]
    }
   ],
   "source": [
    "!cat data/collins_switch.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It has two rows of non-data. Then, Column 1 is the IPTG concentration, column 2 is the normalized GFP expression level, and the last column is the standard error of the mean normalized GFP intensity. This gives the error bars, which we will look at in the next exercise. For now, we will just plot IPTG versus normalized GFP intensity.\n",
    "\n",
    "In looking at the data set, note that there are two entries for [IPTG] = 0.04 mM. At this concentration, the switch happens, and there are two populations of cells, one with high expression of GFP and one with low. The two data points represent these two populations of cells.\n",
    "\n",
    "Now, let's make a plot of IPTG versus GFP.\n",
    "\n",
    ">1. Load in the data set using `np.loadtxt()`. Be sure to use the `delimeter=','` and `skiprows=2` kwargs.\n",
    "2. Slice column 0 out of the data and store it as `iptg`.\n",
    "3. Slice column 1 out of the data and store it as `gfp`.\n",
    "4. Make a plot of normalized GFP intensity ($y$-axis) versus IPTG concentration ($x$-axis) using Matplotlib's `plot()` function. These are data, so you should not make the plot as lines. Use the `marker='.'` and `linestyle='none'` kwargs.\n",
    "5. Label your axes.\n",
    "\n",
    "Now that you have done that, there are some problems with the plot. It is really hard to see the data points with low concentrations of IPTG. In fact, looking at the data set, the concentration of IPTG varies over four orders of magnitude. When you have data like this, it is wise to plot them on a logarithmic scale. You can set the scale to be logarithmic using the `set_xscale()` method.\n",
    "\n",
    "    ax.set_xscale('log')\n",
    "\n",
    "For this data set, it is best to have the $x$ axis on a logarithmic scale. Remake the plot you just did with a logarithmically scaled $x$-axis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice 2: Plots with error bars\n",
    "\n",
    "The data set also contains the standard error of the mean, or SEM. The SEM is often displayed on plots as error bars. To make a plot with error bars, you can use the `plt.errorbar()` function.\n",
    ">1. Read [the documentation of `plt.errorbar()`](http://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.errorbar).\n",
    "2. Slice column 2 out of the Collins data set and store it as `sem`.\n",
    "3. Make a plot of the genetic switch data using `ax.errorbar()` setting the kwarg `yerr=sem`.\n",
    "4. Label your axes.\n",
    "\n",
    "There is also a problem with the GFP signals at low IPTG. The error bars are tiny, so it is hard to see the symbol. Now, play with different kwargs to make your error bar plot look the way you like. I recommend these kwargs:\n",
    "* `linestyle='none'`\n",
    "* `marker='.'`\n",
    "* `markersize=10`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice 3: Computing and plotting ECDFs\n",
    "\n",
    "We plotted the measured cross-sectional areas of the *C. elegans* eggs from the Harvey and Orbidans paper as histograms. A histogram is a way of approximately representing the *probability distribution function*, or PDF, describing the data. The *cumulative distribution function*, or CDF, contains the same information as the PDF. It's just its integral. Importantly, we can plot the data to show what the CDF looks like, the so-called *empirical cumulative distribution function*, or ECDF, without the binning bias inherent in histograms.\n",
    "\n",
    "To plot an ECDF, the $x$-values are the sorted values of the array of data.  The values of the $y$ axis are $y_j = (j+1) / n$, where $n$ is the number of data points and $0 \\le j \\le n-1$.\n",
    "\n",
    ">1. Write a function to compute the ECDF. The call signature is `ecdf(data)`. It returns the `x` and `y` values needed to plot the ECDF.\n",
    "    * Compute `x` by sorting the array `data`.\n",
    "    * Compute `y`. Think carefully about how to do this. The two functions you need are `np.arange()` and `len()`.\n",
    "    * Return `x,y`.\n",
    "2. Load in the data sets `xa_high_food.csv` and `xa_low_food.csv`.\n",
    "3. Generate `x` and `y` values for the ECDFs for these data sets.\n",
    "4. Plot the ECDFs got the high food and low food data as dots. That is, use the kwargs `marker='.'` and `linestyle='none'` when you call `ax.plot()`. Note that to add additional plots to a given figure, you just call `ax.plot()` again. Be sure to label your axes. \"ECDF\" is a reasonable label for your $y$-axis.\n",
    "\n",
    "I think far too few papers use ECDFs in displaying data. They are far better then histograms. I hope that now you have found them, you will use them in your own research."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice 4: Setting up the bootcamp_utils module\n",
    "\n",
    "Speaking of your own work, hopefully what you will use some of the code you write here in bootcamp going forward. As such, set up a module, `bootcamp_utils` that contains some nice functions you write as you go through the bootcamp. We'll start with `ecdf()`.\n",
    "\n",
    ">1. Use Atom to open the file `~/git/bootcamp/bootcamp_utils.py`.\n",
    "2. Put an appropriate doc string at the top.\n",
    "3. Import Numpy at the top. Later on, as you add more functions, you might need to include more imports.\n",
    "4. Put your code for your `ecdf()` function in that file.\n",
    "5. Save and close the file.\n",
    "6. Use `git add` to put `bootcamp_utils.py` under version control.\n",
    "7. Use `git commit` to commit it. Don't forget the `-m` flag and your commit message.\n",
    "8. Use `git push origin master` to push your changes to the repository. Remember, you are working on your own fork, so there will be no conflicts with the upstream repository or with your classmates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice 5: Are they Normally distributed?\n",
    "\n",
    "We might be interested to see if the egg cross-section data follow a Normal distribution. After all, this is commonly an underlying assumption when people report data from repeated measurements in the literature.\n",
    "\n",
    "One way to assess this is to plot the theoretical CDF with the same mean and standard deviation as the data on top of the ECDFs. (There are better graphical ways to do this, but this is ok for our purposes here.)  We know the cumulative distribution function for a Normal distribution with mean $\\mu$ and standard deviation $\\sigma$ is\n",
    "\n",
    "\\begin{align}\n",
    "\\mathrm{cdf}(x) = \\frac{1}{2}\\left(1 + \\mathrm{erf}\\left(\\frac{x - \\mu}{\\sqrt{2\\sigma^2}}\\right)\\right),\n",
    "\\end{align}\n",
    "\n",
    "but instead of coding this up directly, we can use the `scipy.stats` to do it for us!  We just need to supply where we want it evaluated ($x$), and the mean (the location parameter) and standard deviation (the scale parameter). Something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make smooth x-values\n",
    "x = np.linspace(1600, 2500, 400)\n",
    "\n",
    "# Compute theoretical Normal distribution\n",
    "cdf_theor = scipy.stats.norm.cdf(x, loc=np.mean(xa_low), scale=np.std(xa_low))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's make the plot.\n",
    "\n",
    ">1. Regenerate your ECDFs. This time, import the `bootcamp_utils` module and call `bootcamp_utils.ecdf()` to get your `x` and `y` values.\n",
    "2. Make smooth curves of the Normal CDF using `scipy.stats.norm.cdf()`.\n",
    "3. Plot those curves using `ax.plot()`. You can use the `color='gray'` keyword argument to set the color of the smooth curves. Note that we plot the smooth curves first, and then the ECDFs (which are the raw data) so that the smooth curves do not obscure the data.\n",
    "4. Plot the ECDFs as dots, as before. Use the `label` kwarg to name these ECDFs, e.g., with `label='high food'`.\n",
    "5. Make a legend. If any graphic object created with `ax.plot()` was made with a `label` kwarg, only those that were so made show up in the legend. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
